{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "475d89fb",
   "metadata": {},
   "source": [
    "## Essencial Functions and Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45965918",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import tifffile as tiff\n",
    "from difflib import get_close_matches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ff89d4",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12af8384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final: 391 pairs loaded.\n",
      "Shape of imgs: (391, 512, 512, 4)\n",
      "Shape of masks: (391, 512, 512)\n"
     ]
    }
   ],
   "source": [
    "# Main dataset directory\n",
    "dataset_dir = Path('spotlite_dataset_loca1_date1_dir1')\n",
    "\n",
    "images_dir = dataset_dir / 'images'\n",
    "masks_dir = dataset_dir / 'masks'\n",
    "\n",
    "assert images_dir.exists(), f\"Image folder not found: {images_dir}\"\n",
    "assert masks_dir.exists(), f\"Mask folder not found: {masks_dir}\"\n",
    "\n",
    "# Collect all image and mask files (multiple extensions)\n",
    "image_paths = sorted(\n",
    "    [*images_dir.glob('*.tif'), *images_dir.glob('*.tiff')],\n",
    "    key=lambda p: p.stem\n",
    ")\n",
    "mask_paths = sorted(\n",
    "    [*masks_dir.glob('*.tif'), *masks_dir.glob('*.tiff'),\n",
    "     *masks_dir.glob('*.png'), *masks_dir.glob('*.jpg')],\n",
    "    key=lambda p: p.stem\n",
    ")\n",
    "\n",
    "# Dictionary of masks by base name\n",
    "mask_dict = {p.stem: p for p in mask_paths}\n",
    "unused_masks = set(mask_dict.keys())\n",
    "\n",
    "imgs_array, masks_array = [], []\n",
    "\n",
    "for img_path in image_paths:\n",
    "    stem = img_path.stem\n",
    "    mask_path = None\n",
    "\n",
    "    # 1) Exact match\n",
    "    if stem in mask_dict:\n",
    "        mask_path = mask_dict[stem]\n",
    "        unused_masks.discard(stem)\n",
    "    else:\n",
    "        # 2) Approximate match\n",
    "        candidates = get_close_matches(stem, mask_dict.keys(), n=1, cutoff=0.6)\n",
    "        if candidates:\n",
    "            sel = candidates[0]\n",
    "            mask_path = mask_dict[sel]\n",
    "            unused_masks.discard(sel)\n",
    "        else:\n",
    "            # 3) No match found; just notify and skip\n",
    "            print(f\"Warning: no mask found for {img_path.name}; skipping.\")\n",
    "            continue\n",
    "\n",
    "    # Read image and mask\n",
    "    img = tiff.imread(str(img_path))\n",
    "    msk = tiff.imread(str(mask_path))\n",
    "\n",
    "    # Check dimensions\n",
    "    if img.shape[:2] != msk.shape:\n",
    "        raise ValueError(\n",
    "            f\"Incompatible dimensions: {img_path.name} {img.shape[:2]} vs \"\n",
    "            f\"{mask_path.name} {msk.shape}\"\n",
    "        )\n",
    "\n",
    "    imgs_array.append(img)\n",
    "    masks_array.append(msk)\n",
    "\n",
    "# Remaining masks\n",
    "if unused_masks:\n",
    "    print(\"Warning: these masks were not used (no corresponding image):\")\n",
    "    for s in sorted(unused_masks):\n",
    "        print(\"  \", s)\n",
    "\n",
    "# Stack arrays\n",
    "imgs = np.stack(imgs_array, axis=0)   # (N, H, W, C)\n",
    "masks = np.stack(masks_array, axis=0)  # (N, H, W)\n",
    "\n",
    "print(f'Final: {len(imgs)} pairs loaded.')\n",
    "print(f'Shape of imgs: {imgs.shape}')\n",
    "print(f'Shape of masks: {masks.shape}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58aa7752",
   "metadata": {},
   "source": [
    "## Analyse Vegetation Annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb61850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis with NDVI threshold 0.2:\n",
      "vegetation_estimated: 37.0%\n",
      "vegetation_annotated: 2.0%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def analyze_total_subannotation(imgs, masks, ndvi_threshold=0.2, classes_vegetation=[2, 3, 4]): \n",
    "    N, H, W, C = imgs.shape\n",
    "    R = imgs[:, :, :, 0]\n",
    "    NIR = imgs[:, :, :, 3]\n",
    "    \n",
    "    NDVI = (NIR - R) / (NIR + R + 1e-5)\n",
    "    veg_estimated = (NDVI > ndvi_threshold).astype(np.uint8)\n",
    "    veg_annotated = np.isin(masks, classes_vegetation).astype(np.uint8)\n",
    "\n",
    "    total_pixels = masks.size\n",
    "    n_estimated = veg_estimated.sum()\n",
    "    n_annotated = veg_annotated.sum()\n",
    "\n",
    "    result = {\n",
    "        'vegetation_estimated': round(100 * n_estimated / total_pixels, 0) if total_pixels > 0 else 0.0,\n",
    "        'vegetation_annotated': round(100 * n_annotated / total_pixels, 0) if total_pixels > 0 else 0.0,\n",
    "    }\n",
    "\n",
    "    return result\n",
    "\n",
    "# This threshold attempts to separate real vegetation from soil, shadows, or built-up areas.\n",
    "# | NDVI          | Interpretation                        |\n",
    "# | ------------- | ------------------------------------- |\n",
    "# | < 0           | Water, clouds, dense shadows          |\n",
    "# | 0.0 – 0.1     | Exposed soil, rocks                   |\n",
    "# | **0.2 – 0.3** | Sparse or sparse vegetation           |\n",
    "# | **0.3 – 0.6** | Moderate vegetation (grass, shrubs)   |\n",
    "# | **> 0.6**     | Dense vegetation (healthy forests)    |\n",
    "\n",
    "# Why is 0.2 a safe value to detect vegetation?\n",
    "# It is a conservative cutoff point: it already captures light or sparse vegetation.\n",
    "# Avoids excluding weak or young vegetation (which would have NDVI between 0.2 and 0.4).\n",
    "# It is ideal for making general vegetation estimates over large areas.\n",
    "\n",
    "THRESHOLD = 0.2 # conservative threshold\n",
    "\n",
    "result = analyze_total_subannotation(imgs, masks, ndvi_threshold=THRESHOLD)\n",
    "\n",
    "print(f\"Analysis with NDVI threshold {THRESHOLD}:\")\n",
    "\n",
    "for key, value in result.items():\n",
    "    print(f\"{key}: {value}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
