{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "475d89fb",
   "metadata": {},
   "source": [
    "## Essencial Functions and Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45965918",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from tifffile import imread\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Main directory\n",
    "dataset_dir        = 'spotlite_dataset_loca1_date1_dir1'\n",
    "images_dataset_dir = os.path.join(dataset_dir, 'images')\n",
    "masks_dataset_dir  = os.path.join(dataset_dir, 'masks')\n",
    "\n",
    "def load_dataset_stage(images_dir, masks_dir, stage=1, max_patches=None, seed=42, min_forest_pixels=200):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    img_files = sorted([f for f in os.listdir(images_dir)\n",
    "                        if f.endswith('.tif') and not f.endswith('_mask.tif')])\n",
    "    msk_files = sorted([f for f in os.listdir(masks_dir)\n",
    "                        if f.endswith('_mask.tif')])\n",
    "\n",
    "    img_bases = {os.path.splitext(f)[0]: f for f in img_files}\n",
    "    msk_bases = {os.path.splitext(f)[0].replace('_mask',''): f for f in msk_files}\n",
    "    common = sorted(set(img_bases) & set(msk_bases))\n",
    "\n",
    "    forest, background = [], []\n",
    "\n",
    "    for base in common:\n",
    "        img_path = os.path.join(images_dir, img_bases[base])\n",
    "        msk_path = os.path.join(masks_dir, msk_bases[base])\n",
    "        mask = imread(msk_path)\n",
    "        unique_classes, counts = np.unique(mask, return_counts=True)\n",
    "        class_count = dict(zip(unique_classes, counts))\n",
    "\n",
    "        # Stage 1 - Background vs Forest\n",
    "        if stage == 1:\n",
    "            forest_pixels = sum(class_count.get(c, 0) for c in [2, 3, 4])\n",
    "            background_pixels = sum(class_count.get(c, 0) for c in [1, 5])\n",
    "\n",
    "            if forest_pixels >= min_forest_pixels:\n",
    "                forest.append((img_path, msk_path))\n",
    "            elif background_pixels > 100:  # avoid patches that are completely empty (pure class 0)\n",
    "                background.append((img_path, msk_path))\n",
    "\n",
    "        # Stage 2 - only if it contains class 3 or 4 (pine or eucalyptus)\n",
    "        elif stage == 2:\n",
    "            if 3 in unique_classes or 4 in unique_classes:\n",
    "                forest.append((img_path, msk_path))  # only forest matters here\n",
    "\n",
    "    # Balancing Stage 1\n",
    "    if stage == 1:\n",
    "        min_len = min(len(forest), len(background))\n",
    "        random.shuffle(forest)\n",
    "        random.shuffle(background)\n",
    "        selected = forest[:min_len] + background[:min_len]\n",
    "    else:\n",
    "        selected = forest  # Stage 2\n",
    "\n",
    "    # Limit patches\n",
    "    if max_patches:\n",
    "        random.shuffle(selected)\n",
    "        selected = selected[:max_patches]\n",
    "\n",
    "    # Load data\n",
    "    imgs, msks = [], []\n",
    "    for img_path, msk_path in selected:\n",
    "        img = imread(img_path)\n",
    "        msk = imread(msk_path)\n",
    "\n",
    "        if img.ndim == 3 and img.shape[0] in (3, 4):\n",
    "            img = img.transpose(1, 2, 0)\n",
    "        if img.ndim == 2:\n",
    "            img = np.stack([img]*3, axis=-1)\n",
    "\n",
    "        imgs.append(img)\n",
    "        msks.append(msk)\n",
    "\n",
    "    return np.stack(imgs, axis=0), np.stack(msks, axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ff7dca",
   "metadata": {},
   "source": [
    "## Features and split train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68e60f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_pixel_samples(X_patches, y_patches, classes=[1, 3, 4], max_per_class=None, seed=42):\n",
    "    np.random.seed(seed)\n",
    "    class_pixels = []\n",
    "\n",
    "    for cls in classes:\n",
    "        # Boolean mask where the current class is located\n",
    "        mask = (y_patches == cls)\n",
    "        idxs = np.where(mask)\n",
    "\n",
    "        # Extract pixels\n",
    "        X_cls = X_patches[idxs]\n",
    "        y_cls = np.full(X_cls.shape[0], cls, dtype=np.uint8)\n",
    "\n",
    "        # Subsampling (class balancing)\n",
    "        if max_per_class and X_cls.shape[0] > max_per_class:\n",
    "            sel = np.random.choice(X_cls.shape[0], size=max_per_class, replace=False)\n",
    "            X_cls = X_cls[sel]\n",
    "            y_cls = y_cls[sel]\n",
    "\n",
    "        class_pixels.append((X_cls, y_cls))\n",
    "\n",
    "    # Concatenate all classes\n",
    "    X_final = np.concatenate([x for x, _ in class_pixels], axis=0)\n",
    "    y_final = np.concatenate([y for _, y in class_pixels], axis=0)\n",
    "\n",
    "    return X_final, y_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa42d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load patches for Stage 1\n",
    "X1_patches, y1_patches = load_dataset_stage(images_dataset_dir, masks_dataset_dir, stage=1)\n",
    "\n",
    "# 2. Split train/test by patch\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "idx = np.arange(X1_patches.shape[0])\n",
    "train_idx, test_idx = train_test_split(idx, test_size=0.2, random_state=42)\n",
    "\n",
    "X1_train_patches, y1_train_patches = X1_patches[train_idx], y1_patches[train_idx]\n",
    "X1_test_patches,  y1_test_patches  = X1_patches[test_idx],  y1_patches[test_idx]\n",
    "\n",
    "# 3. Extract pixels by class (with balancing)\n",
    "X1_train, y1_train = extract_pixel_samples(X1_train_patches, y1_train_patches, classes=[1,3,4], max_per_class=50000)\n",
    "X1_test,  y1_test  = extract_pixel_samples(X1_test_patches,  y1_test_patches,  classes=[1,3,4], max_per_class=20000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0dca5b",
   "metadata": {},
   "source": [
    "### Train Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676a99d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, ConfusionMatrixDisplay\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def train_two_stage_rf(X1, y1, X2, y2, forest_params, species_params):\n",
    "    # Stage 1: Forest vs Background\n",
    "    # background = classe 1 → 0 ; floresta = classe 3 ou 4 → 1\n",
    "    y1_bin = (y1 != 1).astype(int)\n",
    "    forest_clf = RandomForestClassifier(**forest_params)\n",
    "    forest_clf.fit(X1, y1_bin)\n",
    "\n",
    "    # Stage 2: y2 já contém só classes 3 e 4\n",
    "    species_clf = RandomForestClassifier(**species_params)\n",
    "    species_clf.fit(X2, y2)\n",
    "\n",
    "    return forest_clf, species_clf\n",
    "\n",
    "def predict_two_stage_rf(forest_clf, species_clf, X):\n",
    "    is_forest = forest_clf.predict(X).astype(bool)\n",
    "    y_pred = np.full(X.shape[0], 1, dtype=int)  # Default: background = 1\n",
    "\n",
    "    if is_forest.any():\n",
    "        y_pred[is_forest] = species_clf.predict(X[is_forest])\n",
    "\n",
    "    return y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef0484c",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_params = {\n",
    "    'n_estimators': 100,\n",
    "    'max_depth': 20,\n",
    "    'class_weight': 'balanced',  \n",
    "    'n_jobs': -1,                \n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "species_params = {\n",
    "    'n_estimators': 100,\n",
    "    'max_depth': 20,\n",
    "    'class_weight': 'balanced', \n",
    "    'n_jobs': -1,\n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# 2. Separar os patches em treino/teste\n",
    "idx2 = np.arange(X2_patches.shape[0])\n",
    "train_idx2, test_idx2 = train_test_split(idx2, test_size=0.2, random_state=42)\n",
    "\n",
    "X2_train_patches = X2_patches[train_idx2]\n",
    "y2_train_patches = y2_patches[train_idx2]\n",
    "X2_test_patches  = X2_patches[test_idx2]\n",
    "y2_test_patches  = y2_patches[test_idx2]\n",
    "\n",
    "# 3. Extrair vetores por pixel (apenas classes 3 e 4)\n",
    "X2_train, y2_train = extract_pixel_samples(\n",
    "    X2_train_patches, y2_train_patches,\n",
    "    classes=[3, 4], max_per_class=30000\n",
    ")\n",
    "\n",
    "X2_test, y2_test = extract_pixel_samples(\n",
    "    X2_test_patches, y2_test_patches,\n",
    "    classes=[3, 4], max_per_class=15000\n",
    ")\n",
    "\n",
    "forest_clf, species_clf = train_two_stage_rf(\n",
    "    X1_train, y1_train,  # Stage 1: fundo vs floresta\n",
    "    X2_train, y2_train,  # Stage 2: pinus vs eucalipto\n",
    "    forest_params, species_params\n",
    ")\n",
    "\n",
    "# Predição completa\n",
    "y_pred_full = predict_two_stage_rf(forest_clf, species_clf, X1_test)\n",
    "\n",
    "# Prediction\n",
    "y_pred_full = predict_two_stage_rf(forest_clf, species_clf, X1_test)\n",
    "\n",
    "# Stage 1 - Evaluation\n",
    "y_forest_true = np.isin(y1_test, [2, 3, 4]).astype(int)\n",
    "y_forest_pred = forest_clf.predict(X1_test)\n",
    "print(\"=== Stage 1: Background vs. Forest ===\")\n",
    "print(classification_report(\n",
    "    y_forest_true, y_forest_pred,\n",
    "    target_names=['Background', 'Forest'], digits=4\n",
    "))\n",
    "\n",
    "# Stage 2 - Evaluation (isolated where ground truth is forest 3 or 4)\n",
    "mask_fg = np.isin(y2_test, [3, 4])\n",
    "X_test_fg = X2_test[mask_fg]\n",
    "y_test_fg = y2_test[mask_fg]\n",
    "y_pred_fg = species_clf.predict(X_test_fg)\n",
    "print(\"=== Stage 2: Pinus vs. Eucalyptus (isolated) ===\")\n",
    "print(classification_report(\n",
    "    y_test_fg, y_pred_fg,\n",
    "    target_names=['Pinus', 'Eucalyptus'], digits=4\n",
    "))\n",
    "\n",
    "# Final Evaluation  (3 classes)\n",
    "print(\"=== Full Pipeline: 3 classes (1=BG, 3=Pinus, 4=Eucalipto) ===\")\n",
    "print(classification_report(\n",
    "    y1_test, y_pred_full,\n",
    "    labels=[1, 3, 4],\n",
    "    target_names=['Background', 'Pinus', 'Eucalyptus'],\n",
    "    digits=4\n",
    "))\n",
    "\n",
    "ConfusionMatrixDisplay.from_predictions(\n",
    "    y1_test, y_pred_full,\n",
    "    labels=[1, 3, 4],\n",
    "    display_labels=['Background', 'Pinus', 'Eucalyptus'],\n",
    "    normalize='true',\n",
    "    values_format='.2f'\n",
    ")\n",
    "plt.title(\"Confusion Matrix — Random Forest 3-class (Normalized)\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
